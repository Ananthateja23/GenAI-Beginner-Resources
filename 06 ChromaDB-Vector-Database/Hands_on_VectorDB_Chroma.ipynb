{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-s0vQkLdb2O"
      },
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMzsPMT1pEcX"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw4HTBM0pboI"
      },
      "outputs": [],
      "source": [
        "!unzip -q new_articles.zip -d new_articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha4Xa3CSbcvj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-openai langchain-chroma chromadb langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04V77OqZb4Ve"
      },
      "outputs": [],
      "source": [
        "!pip show langchain langchain-openai langchain-chroma chromadb langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKA4pBiAd72J"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0qKrx75eY6c"
      },
      "outputs": [],
      "source": [
        "!cat requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx9ZxjFEeYoM"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('requirements.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m5jituSbi2y"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8vkbEtSbHsr"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OGLyJHlCw9I"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6Vp9Z97dvYk"
      },
      "outputs": [],
      "source": [
        "# Load documents\n",
        "loader = DirectoryLoader(\"/content/new_articles/\", glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz8AGrgsefHn"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# Split documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbiwepwOFciL"
      },
      "outputs": [],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkliDSQeFgzq"
      },
      "outputs": [],
      "source": [
        "texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxZpU93dFj80"
      },
      "outputs": [],
      "source": [
        "texts[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZT72Bznjy4h"
      },
      "source": [
        "## Creating DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlIiuTdTScoe"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain langchain-openai langchain-chroma chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5Hxtsb9Vbs9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE_5nV4XVHO3"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 1) Create the embedding model\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key = OPENAI_API_KEY)\n",
        "\n",
        "# 2) Persist directory for storing the vector DB\n",
        "persist_directory = \"db\"\n",
        "\n",
        "# 3) Create and persist the vector store from documents\n",
        "vectordb = Chroma(\n",
        "    collection_name=\"my_collection\",               # required\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=persist_directory            # enables persistence\n",
        ")\n",
        "\n",
        "\n",
        "# Add documents to the vector DB\n",
        "# documents should be a list of Document objects\n",
        "vectordb.add_documents(documents = texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ViOXO6gXARG"
      },
      "outputs": [],
      "source": [
        "# Save changes\n",
        "# vectordb.persist()\n",
        "\n",
        "# Clear in-memory reference\n",
        "vectordb = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaQt6-hpYHIL"
      },
      "outputs": [],
      "source": [
        "# 4) Load the persisted DB back from disk\n",
        "vectordb = Chroma(\n",
        "    collection_name=\"my_collection\",               # same collection name\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2iBuuzMp7iB"
      },
      "source": [
        "## Make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JuHVjIbYLAp"
      },
      "outputs": [],
      "source": [
        "# 5) Create a retriever\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "# 6) Get relevant docs for a query\n",
        "docs = retriever.invoke(\"How much money did Microsoft raise?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2JwsQxuppol"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLhSQlBfpvxB"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et_NO2KyY3m6"
      },
      "outputs": [],
      "source": [
        "# 7) Example of customizing search parameters\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
        "\n",
        "# You can inspect these values\n",
        "print(retriever.search_type)\n",
        "print(retriever.search_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OnCpk2XqILs"
      },
      "outputs": [],
      "source": [
        "retriever.search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU1N3Tg_qNA6"
      },
      "outputs": [],
      "source": [
        "retriever.search_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nszy1qArqUDD"
      },
      "source": [
        "## Make a chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzW7I3hQrm8f"
      },
      "outputs": [],
      "source": [
        "# !pip show langchain langchain-openai langchain-chroma chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF94sH6Gt81s"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn6nTXyMvdS2"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqUHmxoZxSYc"
      },
      "outputs": [],
      "source": [
        "# !pip show langchain langchain-openai langchain-chroma chromadb langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5s0ebKfyxlg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jg-9f6PVqEVB"
      },
      "outputs": [],
      "source": [
        "# 1️) LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, api_key = OPENAI_API_KEY)\n",
        "\n",
        "# 2️) Prompt template\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Answer the question using ONLY the context below.\n",
        "    If the answer is not in the context, say \"I don't know\".\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 3️) LCEL RAG Chain\n",
        "\n",
        "full_rag_chain = (\n",
        "    RunnablePassthrough.assign(context=itemgetter(\"question\") | retriever)\n",
        "    | {\n",
        "        \"answer\": prompt | llm | StrOutputParser(),\n",
        "        \"context\": itemgetter(\"context\")\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob82_IqEqzyp"
      },
      "outputs": [],
      "source": [
        "# 4) Helper function\n",
        "def process_llm_response(response):\n",
        "    print(\"Answer:\\n\")\n",
        "    print(response[\"answer\"])\n",
        "    print(\"\\nSources:\")\n",
        "    for doc in response[\"context\"]:\n",
        "        source = doc.metadata.get(\"source\", \"Unknown source\")\n",
        "        print(f\"- {source}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSQd47v0qzgW"
      },
      "outputs": [],
      "source": [
        "# Full example\n",
        "query = \"How much money did Microsoft raise?\"\n",
        "response = full_rag_chain.invoke({\"question\": query})\n",
        "process_llm_response(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "athwnfghq6si"
      },
      "outputs": [],
      "source": [
        "# Another query\n",
        "query = \"What is the news about Pando?\"\n",
        "response = full_rag_chain.invoke({\"question\": query})\n",
        "process_llm_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov_bVjCL0Gdx"
      },
      "source": [
        "## Deleteing the DB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vTIwx7R-FtI"
      },
      "outputs": [],
      "source": [
        "!zip -r db.zip ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_cg_gmQ1M5A"
      },
      "outputs": [],
      "source": [
        "# 1. Access the underlying client to delete\n",
        "try:\n",
        "    vectordb._client.delete_collection(\"my_collection\")\n",
        "    print(\"Collection deleted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Collection might not exist: {e}\")\n",
        "\n",
        "# 2. Manual directory cleanup (Optional but recommended for a total reset)\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "db_path = \"db\"\n",
        "if os.path.exists(db_path):\n",
        "    shutil.rmtree(db_path)\n",
        "    print(\"Database directory removed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U57wq4Rd1XTw"
      },
      "source": [
        "## Starting again loading the db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzvFYeJ81TUS"
      },
      "outputs": [],
      "source": [
        "!unzip db.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1QC7S5xfb8S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
